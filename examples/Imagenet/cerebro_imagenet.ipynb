{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebro.etl.etl_spec import ETLSpec\n",
    "from cerebro.experiment import Experiment\n",
    "from cerebro.mop.minibatch_spec import MiniBatchSpec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetETLSpec(ETLSpec):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "\n",
    "    def read_misc(self, misc_path):\n",
    "        pass\n",
    "\n",
    "    def set_features(self):\n",
    "        return [False, False, True, False, False]\n",
    "    \n",
    "    def row_prep(self, row, mode, object_dir):\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "\n",
    "        input_image_path = object_dir + \"/\" + str(row[\"filepath\"])\n",
    "\n",
    "        pil_image = Image.open(input_image_path)\n",
    "        image = np.asarray(pil_image.convert('RGB').resize((112, 112)))\n",
    "        image = image / 255.0\n",
    "        image = image - [0.485, 0.456, 0.406]\n",
    "        image = image / [0.229, 0.224, 0.225]\n",
    "\n",
    "        torch_image = torch.from_numpy(image).float()\n",
    "        image = torch.reshape(torch_image, (torch_image.shape[2], torch_image.shape[0], torch_image.shape[1]))\n",
    "        if mode == 'predict':\n",
    "            return image, None\n",
    "        else:\n",
    "            label = torch.tensor(row[\"label\"])\n",
    "            return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTrainingSpec(MiniBatchSpec):\n",
    "    def __init__(self):\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.log_softmax = torch.nn.LogSoftmax()\n",
    "\n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "    \n",
    "    def read_misc(self, misc_path):\n",
    "        import os\n",
    "        import json\n",
    "        \n",
    "        path = os.path.join(misc_path, \"imagenet_label_mapping.json\")\n",
    "        with open(path) as f:\n",
    "            self.class_to_idx = json.load(f) \n",
    "\n",
    "    def create_model_components(self, hyperparams):\n",
    "        import torch\n",
    "        import warnings\n",
    "        from torchvision import models\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        learning_rate = hyperparams[\"learning_rate\"]\n",
    "        lambda_value = hyperparams[\"lambda_value\"]\n",
    "        model_type = hyperparams[\"model_type\"]\n",
    "\n",
    "        if model_type == \"resnet50\":\n",
    "            model = models.resnet50(pretrained=False)\n",
    "        elif model_type == \"vgg16\":\n",
    "            model = models.vgg16(pretrained=False)\n",
    "        else:\n",
    "            model = None\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=learning_rate,\n",
    "                                     weight_decay=lambda_value)\n",
    "\n",
    "        model_object = {\n",
    "            \"imagenet_model\": model,\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "\n",
    "        return model_object\n",
    "\n",
    "    def accuracy(self, output, target, topk=(1,), binary=False):\n",
    "        import torch\n",
    "\n",
    "        \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "        if binary:\n",
    "            batch_size = target.size(0)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct = (pred == target).sum().item()\n",
    "            res = [torch.tensor(correct / batch_size)]\n",
    "        else:\n",
    "            maxk = max(topk)\n",
    "            maxk = min(maxk, output.shape[1])\n",
    "            batch_size = target.size(0)\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "            res = []\n",
    "            for k in topk:\n",
    "                correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "                res.append(correct_k.mul_(1.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "    def metrics_agg(self, mode, hyperparams, metrics):\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "        updated_metrics = {}\n",
    "        if mode == \"train\":\n",
    "            updated_metrics = {\n",
    "                \"epoch_loss\": sum(metrics[\"minibatch_loss\"]) / (batch_size * len(metrics)),\n",
    "                \"epoch_top_1_acc\": sum(metrics[\"minibatch_top_1_acc\"]) / len(metrics),\n",
    "                \"epoch_top_5_acc\": sum(metrics[\"minibatch_top_5_acc\"]) / len(metrics)\n",
    "            }\n",
    "\n",
    "            stats = \"Train Metrics: epoch_loss: %.4f, epoch_top_1_acc: %5.4f, , epoch_top_5_acc: %5.4f\"\\\n",
    "                    % (updated_metrics[\"epoch_loss\"], updated_metrics[\"epoch_top_1_acc\"],\n",
    "                       updated_metrics[\"epoch_top_5_acc\"])\n",
    "            print(stats)\n",
    "\n",
    "        elif mode == \"val\" or mode == \"test\":\n",
    "            updated_metrics = {\n",
    "                \"epoch_loss\": sum(metrics[\"epoch_loss\"]) / (batch_size * len(metrics)),\n",
    "                \"epoch_top_1_acc\": sum(metrics[\"epoch_top_1_acc\"]) / len(metrics),\n",
    "                \"epoch_top_5_acc\": sum(metrics[\"epoch_top_5_acc\"]) / len(metrics)\n",
    "            }\n",
    "\n",
    "            stats = \"Validation/Test Metrics:  loss: %.4f, top_1_acc: %5.4f, , top_5_acc: %5.4f\" \\\n",
    "                    % (updated_metrics[\"epoch_loss\"], updated_metrics[\"epoch_top_1_acc\"],\n",
    "                       updated_metrics[\"epoch_top_5_acc\"])\n",
    "            print(stats)\n",
    "\n",
    "        return updated_metrics\n",
    "\n",
    "    def train(self, model_object, minibatch, hyperparams, device):\n",
    "        import torch\n",
    "\n",
    "        model = model_object[\"imagenet_model\"]\n",
    "        optimizer = model_object[\"optimizer\"]\n",
    "        model.train()\n",
    "        \n",
    "        model.to(device)\n",
    "        images, labels = minibatch[0].to(device), torch.tensor(minibatch[1]).to(device)\n",
    "        outputs = model(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        outputs_softmax = self.log_softmax(outputs)\n",
    "        \n",
    "        # Print the loss value\n",
    "        print(f'Loss: {loss.item()}')\n",
    "\n",
    "        top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "        metrics = {\n",
    "            \"minibatch_loss\": loss.item(),\n",
    "            \"minibatch_top_1_acc\": top_1_acc.item(),\n",
    "            \"minibatch_top_5_acc\": top_5_acc.item()\n",
    "        }\n",
    "\n",
    "        updated_model_object = {\n",
    "            \"imagenet_model\": model,\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "        return updated_model_object, metrics\n",
    "\n",
    "    def val_test(self, model_object, minibatch, hyperparams, device):\n",
    "        import torch\n",
    "\n",
    "        model = model_object[\"imagenet_model\"]\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images, labels = minibatch[0].to(device), torch.tensor(minibatch[1]).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            outputs_softmax = self.log_softmax(outputs)\n",
    "            top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "\n",
    "        metrics = {\n",
    "            \"epoch_loss\": loss.item(),\n",
    "            \"epoch_top_1_acc\": top_1_acc.item(),\n",
    "            \"epoch_top_5_acc\": top_5_acc.item()\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def predict(self, model_object, minibatch, hyperparams, device):\n",
    "        import torch\n",
    "\n",
    "        model = model_object[\"imagenet_model\"]\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "    \n",
    "        images = minibatch[0].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(images)\n",
    "    \n",
    "        probabilities = torch.nn.functional.softmax(output, dim=0)\n",
    "        top_probabilities, top_indices = torch.topk(probabilities, 1)\n",
    "    \n",
    "        # Convert indices to class labels\n",
    "        idx_to_class = {idx: label for label, idx in self.class_to_idx.items()}\n",
    "        top_classes = [idx_to_class[idx.item()] for idx in top_indices]\n",
    "        top_probabilities = [i.item() for i in top_probabilities]\n",
    "    \n",
    "        return top_classes, top_probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Model Building specifications </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "param_grid = {\n",
    "    'batch_size': [128, 256],\n",
    "    'learning_rate': [1e-2, 1e-3],\n",
    "    'lambda_value': [1e-3, 1e-4],\n",
    "    'model_type': ['resnet50']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Initialize Experiment </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"train_main\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Metadata/train.csv\",\n",
    "    \"val_main\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Metadata/valid.csv\",\n",
    "    \"test_main\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Metadata/valid.csv\",\n",
    "    \"predict_main\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Metadata/test.csv\",\n",
    "    \"train_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Data/CLS-LOC/train\",\n",
    "    \"val_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Data/CLS-LOC/val\",\n",
    "    \"test_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Data/CLS-LOC/val\",\n",
    "    \"predict_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/Data/CLS-LOC/test\",\n",
    "    \"misc\": [\n",
    "        \"/voyager/ceph/users/prsridha/datasets/imagenet/Metadata/imagenet_label_mapping.json\"\n",
    "    ],\n",
    "    \"etl_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/ProcessedData\",\n",
    "    \"models_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/SavedModels\",\n",
    "    \"output_dir\": \"/voyager/ceph/users/prsridha/datasets/imagenet/SavedArtifacts\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(params)\n",
    "imagenet_etl_spec = ImagenetETLSpec()\n",
    "imagenet_training_spec = ImagenetTrainingSpec()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_etl(imagenet_etl_spec, fraction=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_fit(imagenet_training_spec, param_grid, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_test(imagenet_training_spec, \"model_3/model_object_3.pt\", 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_predict(imagenet_training_spec, \"model_3/model_object_3.pt\", 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
