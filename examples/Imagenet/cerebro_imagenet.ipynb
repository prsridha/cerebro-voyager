{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Imports</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebro.etl.etl_spec import ETLSpec\n",
    "from cerebro.experiment import Experiment\n",
    "from cerebro.mop.sub_epoch_spec import SubEpochSpec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetETLSpec(ETLSpec):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "\n",
    "    def read_misc(self, misc_path):\n",
    "        pass\n",
    "\n",
    "    def set_features(self):\n",
    "        return [False, False, True, False, False]\n",
    "    \n",
    "    def row_prep(self, row, mode, object_dir):\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        from PIL import Image\n",
    "\n",
    "        input_image_path = object_dir + \"/\" + str(row[\"filepath\"])\n",
    "\n",
    "        pil_image = Image.open(input_image_path)\n",
    "        image = np.asarray(pil_image.convert('RGB').resize((112, 112)))\n",
    "        image = image / 255.0\n",
    "        image = image - [0.485, 0.456, 0.406]\n",
    "        image = image / [0.229, 0.224, 0.225]\n",
    "\n",
    "        torch_image = torch.from_numpy(image).float()\n",
    "        image = torch.reshape(torch_image, (torch_image.shape[2], torch_image.shape[0], torch_image.shape[1]))\n",
    "        if mode == 'predict':\n",
    "            return image, None\n",
    "        else:\n",
    "            label = torch.tensor(row[\"label\"])\n",
    "            return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Initialize Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenetTrainingSpec(SubEpochSpec):\n",
    "    def __init__(self):\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "        self.log_softmax = torch.nn.LogSoftmax().cuda() if torch.cuda.is_available() else torch.nn.LogSoftmax()\n",
    "\n",
    "    def initialize_worker(self):\n",
    "        pass\n",
    "\n",
    "    def create_model_components(self, hyperparams):\n",
    "        import torch\n",
    "        from torchvision import models\n",
    "\n",
    "        learning_rate = hyperparams[\"learning_rate\"]\n",
    "        lambda_value = hyperparams[\"lambda_value\"]\n",
    "        model_type = hyperparams[\"model_type\"]\n",
    "\n",
    "        if model_type == \"resnet50\":\n",
    "            model = models.resnet50(pretrained=False)\n",
    "        elif model_type == \"vgg16\":\n",
    "            model = models.vgg16(pretrained=False)\n",
    "\n",
    "        # Define the optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=learning_rate,\n",
    "                                     weight_decay=lambda_value)\n",
    "\n",
    "        model_object = {\n",
    "            \"imagenet_model\": model,\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "\n",
    "        return model_object\n",
    "\n",
    "    def accuracy(self, output, target, topk=(1,), binary=False):\n",
    "        import torch\n",
    "\n",
    "        \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "        if binary:\n",
    "            batch_size = target.size(0)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct = (pred == target).sum().item()\n",
    "            res = [torch.tensor(correct / batch_size)]\n",
    "        else:\n",
    "            maxk = max(topk)\n",
    "            maxk = min(maxk, output.shape[1])\n",
    "            batch_size = target.size(0)\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "            res = []\n",
    "            for k in topk:\n",
    "                correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "                res.append(correct_k.mul_(1.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "    def metrics_agg(self, mode, hyperparams, metrics):\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "        if mode == \"train\":\n",
    "            updated_metrics = {\n",
    "                \"minibatch_loss\": sum(metrics[\"minibatch_loss\"]) / (batch_size * len(metrics)),\n",
    "                \"minibatch_top_1_acc\": sum(metrics[\"minibatch_top_1_acc\"]) / len(metrics),\n",
    "                \"minibatch_top_5_acc\": sum(metrics[\"minibatch_top_5_acc\"]) / len(metrics)\n",
    "            }\n",
    "\n",
    "            stats = \"Train Metrics: minibatch_loss: %.4f, minibatch_top_1_acc: %5.4f, , minibatch_top_5_acc: %5.4f\"\\\n",
    "                    % (updated_metrics[\"minibatch_loss\"], updated_metrics[\"minibatch_top_1_acc\"],\n",
    "                       updated_metrics[\"minibatch_top_5_acc\"])\n",
    "            print(stats)\n",
    "\n",
    "        elif mode == \"val\":\n",
    "            updated_metrics = {\n",
    "                \"total_epoch_loss\": sum(metrics[\"total_epoch_loss\"]) / (batch_size * len(metrics)),\n",
    "                \"total_epoch_top_1_acc\": sum(metrics[\"total_epoch_top_1_acc\"]) / len(metrics),\n",
    "                \"total_epoch_top_5_acc\": sum(metrics[\"total_epoch_top_5_acc\"]) / len(metrics)\n",
    "            }\n",
    "\n",
    "            stats = \"Validation Metrics:  loss: %.4f, top_1_acc: %5.4f, , top_5_acc: %5.4f\" \\\n",
    "                    % (updated_metrics[\"total_epoch_loss\"], updated_metrics[\"total_epoch_top_1_acc\"],\n",
    "                       updated_metrics[\"total_epoch_top_5_acc\"])\n",
    "            print(stats)\n",
    "\n",
    "        return updated_metrics\n",
    "\n",
    "    def train(self, model_object, minibatch, hyperparams, device):\n",
    "        import torch\n",
    "\n",
    "        model = model_object[\"imagenet_model\"]\n",
    "        optimizer = model_object[\"optimizer\"]\n",
    "        model.train()\n",
    "\n",
    "        images, labels = minibatch[0].to(device), torch.tensor(minibatch[1]).to(device)\n",
    "        outputs = model(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        outputs_softmax = self.log_softmax(outputs)\n",
    "\n",
    "        top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "        metrics = {\n",
    "            \"minibatch_loss\": loss.item(),\n",
    "            \"minibatch_top_1_acc\": top_1_acc.item(),\n",
    "            \"minibatch_top_5_acc\": top_5_acc.item()\n",
    "        }\n",
    "\n",
    "        updated_model_object = {\n",
    "            \"imagenet_model\": model,\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "        return updated_model_object, metrics\n",
    "\n",
    "    def val_test(self, model_object, minibatch, hyperparams, device):\n",
    "        import torch\n",
    "\n",
    "        model = model_object[\"imagenet_model\"]\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images, labels = minibatch[0].to(device), torch.tensor(minibatch[1]).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            outputs_softmax = self.log_softmax(outputs)\n",
    "            top_1_acc, top_5_acc = self.accuracy(outputs_softmax, labels, (1, 5))\n",
    "\n",
    "        metrics = {\n",
    "            \"total_epoch_loss\": loss.item(),\n",
    "            \"total_epoch_top_1_acc\": top_1_acc.item(),\n",
    "            \"total_epoch_top_5_acc\": top_5_acc.item()\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def predict(self, model_object, dataloader, hyperparams, device):\n",
    "        import math\n",
    "        import torch\n",
    "\n",
    "        predictions = []\n",
    "        batch_size = hyperparams[\"batch_size\"]\n",
    "\n",
    "        model = model_object[\"imagenet_model\"]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        minibatch_total_step = math.ceil(len(dataloader.dataset) / batch_size)\n",
    "\n",
    "        batch_num = 1\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                images = batch[0].to(device)\n",
    "                outputs = model(images)\n",
    "                outputs_softmax = self.log_softmax(outputs)\n",
    "                predictions.append(outputs_softmax)\n",
    "\n",
    "                batch_num += 1\n",
    "\n",
    "                stats = \"Test step [%d/%d]\" \\\n",
    "                        % (batch_num, minibatch_total_step)\n",
    "\n",
    "            print(\"\\r\" + stats, end=\"\")\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Model Building specifications </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "param_grid = {\n",
    "    'batch_size': [128, 256],\n",
    "    'learning_rate': [1e-2, 1e-3],\n",
    "    'lambda_value': [1e-3, 1e-4],\n",
    "    'model_type': ['vgg16', 'resnet50']\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Initialize Experiment </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(params)\n",
    "imagenet_etl_spec = ImagenetETLSpec()\n",
    "imagenet_training_spec = ImagenetTrainingSpec()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Data Preprocessing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_etl(imagenet_etl_spec, fraction=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Run Model Building </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_fit(imagenet_training_spec, param_grid, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_test(\"resnet50.pt\", 64, \"test_output.csv\", imagenet_training_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
